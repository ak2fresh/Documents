{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr/>\n",
    "\n",
    "# Data Mining\n",
    "\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><font color=\"darkblue\">Assignment 2</font></h2>\n",
    "\n",
    "For these problems, you can use any python modules including `sklearn`.\n",
    "\n",
    "#### Deadline\n",
    "Homework is due in a week, and should be submitted on Blackboard. Don't wait till the last minute!\n",
    "\n",
    "####  Work alone!\n",
    "Please work on your own solving these assignments! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Problem 1\n",
    "\n",
    "Create a 2D dataset of 200 items containing 3 classes for a classification exercise, which you expect to work well with Quadratic Discriminant Analysis but not with a $7$-Nearest Neighbor classifier. \n",
    "\n",
    "1. Explain your idea before you start coding. Why will it work with QDA but not with the NN? What other $k$ would or wouldn't work? (2 pts)\n",
    "2. Generate the feature sets and labels according to your prescription and plot the features colored by the true class memberships (2 pts)\n",
    "3. Run QDA and NN, and plot the results (2 pts)\n",
    "4. Summarize you findings with your own words: Did you find what you expected? Why? (1 pt)\n",
    "\n",
    "Total of 7 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "Use 10-fold cross-validation to find the best classifier for handwritten digits 0, 1, 2, 3, 4 in the sklearn dataset.\n",
    "\n",
    "1. Try $k$-NN with different $k$ values (1.5 pts)\n",
    "2. Try Gaussian Naive Bayes with different priors (1.5 pts)\n",
    "3. Try different decision trees (1.5 pts)\n",
    "4. Try random forrest classfiers (1.5 pts)\n",
    "5. Which classifer is the best? Why? (1 pt)\n",
    "5. Visualize the (5-by-5) confusion matrix for the best classifier (1 pt)\n",
    "\n",
    "Total of 8 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits(n_class=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
