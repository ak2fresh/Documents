{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr/>\n",
    "\n",
    "# Data Mining\n",
    "**Tamás Budavári** - budavari@jhu.edu <br/>\n",
    "**Class 3** \n",
    "\n",
    "- Sampling from distributions\n",
    "- Density estimation\n",
    "\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><font color=\"darkblue\">Samples, PDFs in 1- and 2-D</font></h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics\n",
    "- Characterization of location, dispersion, etc.\n",
    "\n",
    "| | Sample Estimates <font color=\"white\">(notations)</font> | Probabilisty Density Functions   |\n",
    "|--|--------------|-------------|\n",
    "| **Average** | $\\displaystyle\\ \\bar{x}=\\frac{1}{N}\\sum_{i=1}^N x_i = \\big\\langle x_i \\big\\rangle_{i=1}^N$ | $\\displaystyle\\ \\mu = \\mathbb{E}[X] =\\!\\int\\!x\\,p(x)\\,dx$| \n",
    "| **Variance** | $\\displaystyle\\ s^2=\\frac{1}{N\\!-\\!1}\\sum_{i=1}^N \\big(x_i\\!-\\!\\bar{x}\\big)^2 $|  $\\displaystyle\\ \\mathbb{Var}[X] =\\!\\int\\!(x\\!-\\!\\mu)^2 p(x)\\,dx$| \n",
    "\n",
    "- Useful connection to sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from distributions\n",
    "\n",
    "- Uniform between $a$ and $b$: scale and shift\n",
    "\n",
    ">$\\displaystyle U_{ab} = a + (b\\!-\\!a)\\,U_{01} $\n",
    "\n",
    "- Inverse transform sampling in $\\mathbb{R}$\n",
    "\n",
    ">$\\displaystyle X = \\mathrm{CDF}^{-1}(U_{01}) $\n",
    "\n",
    "> Unhomework: prove it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/inv.png\" height=\"400\" width=\"400\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rejection sampling - also works in $\\mathbb{R}^N$\n",
    "\n",
    "<img src=\"files/anim.gif\" align=left>\n",
    "<!--<img src=\"http://dl.dropbox.com/u/27415200/anim.gif\">-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Numerical Methods\n",
    "If the $\\left\\{x_i\\right\\}$ set is sampled from the probability density function $p(\\cdot)$,\n",
    "the following will be true: (pdf, p(x), is really ugly/difficult to integrate --> approximate)\n",
    "- Average \n",
    "\n",
    ">$\\displaystyle\\mathbb{E}[X] =\\!\\int x\\ p(x)\\,dx  \\ \\approx\\ \\frac{1}{N}\\sum_i x_i $\n",
    "\n",
    "- Variance\n",
    "\n",
    ">$\\displaystyle\\mathbb{E}[(X\\!-\\!\\mu)^2]=\\int (x\\!-\\!\\mu)^2\\ p(x)\\,dx \\approx \\frac{1}{N}\\sum_i (x_i\\!-\\!\\mu)^2$\n",
    "\n",
    "> compare to\n",
    " \n",
    ">$\\displaystyle\\ s^2=\\frac{1}{N\\!-\\!1}\\sum_{i=1}^N \\big(x_i\\!-\\!\\bar{x}\\big)^2 $\n",
    "\n",
    "> mu is true mean, x bar is sample/estimated mean\n",
    "\n",
    "> Bessel correction: $N\\!-\\!1$ independent $(x_i\\!-\\!\\bar{x})$ differences\n",
    "\n",
    ">$\\displaystyle \\sum_{i=1}^N (x_i\\!-\\!\\bar{x}) =\\ ???$ <font color=\"white\">.... 0 ...</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline \n",
    "from scipy.stats import norm as gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9799722851349445, 0.9296833394599175, 0.930012469859987)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sample with size N\n",
    "mu, sigma, N = 0, 1, 10 #tuple assignments\n",
    "x = gaussian.rvs(mu, sigma, N) #gives a bunch of gaussian random numbers\n",
    "\n",
    "avg = np.mean(x)\n",
    "# variance estimates\n",
    "s2   = np.sum( (x-avg)**2 ) /(N-1)  # correct\n",
    "s2n  = np.sum( (x-avg)**2 ) / N     # biased (wrong estimator)\n",
    "s2k  = np.sum( (x- mu)**2 ) / N     # known/true mean\n",
    "\n",
    "# broadcasting (for x-avg above): array minus a scalar does not make sense, so python will make \n",
    "# that scalar into an array of the same size in order to do the subtraction --> read more about this.\n",
    "\n",
    "# standard deviation estimates - should be around 1\n",
    "sqrt(s2), sqrt(s2n), sqrt(s2k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10000) (10000,)\n",
      "(10000,)\n",
      "0.9767855163723475 0.9266601051600927 0.9783810473910404\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate M runs with N samples each\n",
    "mu, sigma, N, M = 0, 1, 10, 10000\n",
    "X = gaussian.rvs(loc=mu, scale=sigma, size=(N,M))\n",
    "avg = np.mean(X, axis=0) #has the 10000 averages\n",
    "print (X.shape, avg.shape)\n",
    "\n",
    "# variance estimates - check out broadcasting in X-avg\n",
    "s2   = np.sum( (X-avg)**2, axis=0) /(N-1) # correct\n",
    "s2n  = np.sum( (X-avg)**2, axis=0) / N    # biased\n",
    "s2k  = np.sum( (X- mu)**2, axis=0) / N    # known/true/cheating mean\n",
    "\n",
    "print (s2.shape)\n",
    "\n",
    "# standard deviation estimates\n",
    "s, sn, sk = np.sqrt(s2), np.sqrt(s2n), np.sqrt(s2k) #tuple assignments\n",
    "print (mean(s), mean(sn), mean(sk))\n",
    "\n",
    "hist(s , 41, range=[0,2], color='r', alpha=0.5); #correct (mode is closest to 1)\n",
    "hist(sn, 41, range=[0,2], color='b', alpha=0.5);\n",
    "grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density Estimation\n",
    "- Histograms (2 parameters)\n",
    "    - Width of bins, $h$\n",
    "    - Start of bin boundary, $x_0$\n",
    "\n",
    " >$\\displaystyle \\mathrm{Hist}(x) = \\frac{1}{N}\\sum_i \\pmb{1}_{\\mathrm{bin}(x_i;x_0,h)}(x)$\n",
    "        \n",
    "- Kernel Density Estimation (KDE): Easier than histograms! (only 1 parameter)\n",
    "    - Bandwidth $h$\n",
    "   \n",
    " >$\\displaystyle \\mathrm{KDE}(x) = \\frac{1}{N}\\sum_i K_h(x\\!-\\!x_i) = \\frac{1}{Nh}\\sum_i K\\left(\\frac{x\\!-\\!x_i}{h}\\right)$\n",
    "   \n",
    "    - Can use different $K(\\cdot)$ kernel functions\n",
    "        - E.g., Uniform, Triangular, Gauss, Epanechnikov\n",
    "\n",
    "See animations at\n",
    "http://www.mglerner.com/blog/?p=28\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Function\n",
    "- Finite vs Infinite support\n",
    "- Numerical evaluations\n",
    "- Frequently used kernels\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/47/Kernels.svg\" alt=\"All of the above kernels in a common coordinate system\"  width=\"350\" align=left>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about KDE \n",
    "[here](https://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/) and also check out Bayesian Blocks \n",
    "[here](https://jakevdp.github.io/blog/2012/09/12/dynamic-programming-in-python/)\n",
    "<br>\n",
    "&mdash; tutorials by Jake Vanderplas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detour: Dirac delta\n",
    "\n",
    "- In the limit of $h\\rightarrow{}0$, the kernel will become strange:\n",
    "\n",
    "<img src=\"files/488px-Dirac_distribution_PDF.svg.png\" align=right width=250>\n",
    "\n",
    "> **Dirac's $\\delta$** \"function\" is 0 everywhere except at 0 such that\n",
    "\n",
    "> $\\displaystyle \\int \\delta(x)\\,dx = 1$\n",
    "\n",
    "- Interesting properties, e.g., \n",
    "\n",
    "> $\\displaystyle \\int f(x)\\,\\delta(x\\!-\\!a)\\,dx = f(a)$\n",
    "\n",
    "-  See **distribution theory** and **functionals** for more background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An interesting result \n",
    "\n",
    "- Bad density estimation but if...\n",
    "\n",
    "> $\\displaystyle p(x) = \\frac{1}{N} \\sum_{i=1}^N \\delta(x\\!-\\!x_i)$\n",
    "\n",
    "- The expectation value\n",
    "\n",
    "> $\\displaystyle \\mathbb{E}[X] =  \\int x\\, \\frac{1}{N} \\sum_{i=1}^N  \\delta(x\\!-\\!x_i) \\,dx$\n",
    "\n",
    "> $\\displaystyle \\mathbb{E}[X] = \\frac{1}{N} \\sum_{i=1}^N \\int x\\, \\delta(x\\!-\\!x_i) \\,dx$\n",
    "\n",
    "> $\\displaystyle \\mathbb{E}[X] = \\frac{1}{N} \\sum_{i=1}^N x_i$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unhomework\n",
    "\n",
    "0. Sample from a mixture of two Gaussians using uniform random numbers in the [0,1) interval. Try different $(\\mu_1, \\sigma_1)$ and $(\\mu_2,\\sigma_2$) values!\n",
    "0. Build different density estimators and compare to the original PDF. Try histogramming and KDE with different parameters."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
